{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "aj5gBXuYVNae"
   },
   "source": [
    "\n",
    " <div style=\"text-align: right; font-size: 10px; color:purple\"> Curso de Especializaci칩n en Inteligencia Artificial y Big Data <br>\n",
    " Programaci칩n de Inteligencia Artificial </div>\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "ceUuJKnLfvEG"
   },
   "source": [
    "# Ejercicio 3: Correspondencias de puntos (칍scar L칩pez Arcos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "916c46c5",
    "outputId": "34aa5c19-36d6-4421-cfa3-035707c4979e"
   },
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "id": "2b4d7f33"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import gdown\n",
    "from matplotlib import pyplot as plt\n",
    "import random as rdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "id": "6QJwHq04pFJ_"
   },
   "source": [
    "En esta actividad vamos a hacer uso de diferentes herramientas que proporciona OpenCV para realizar operaciones y c치lculos sobre im치genes.\n",
    "\n",
    "Primero de todo, vamos a a침adir a nuestro entorno las im치genes necesarias para el desarrollo del ejercicio. Para ello usaremos la librer칤a `gdown`, con el ID de la carpeta p칰blica de Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63Svqr-Og92P",
    "outputId": "2934de63-af85-4b8e-f607-0a898c0305e2"
   },
   "outputs": [],
   "source": [
    "gdown.download_folder(id='1InzY0PJ8QeRE4m_BuOE1pBVfLuGoclN7')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "id": "SxBgdr12qcCm"
   },
   "source": [
    "A continuaci칩n, vamos a definir una serie de constantes que usaremos a lo largo de los diferentes ejercicios, y definir la ruta donde vais a guardar vuestras im치genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "id": "jNJsmW9OwrON"
   },
   "outputs": [],
   "source": [
    "def read_img( filename ):\n",
    "    img = cv2.imread( filename )\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "def show_img( imagen, nombre ):\n",
    "    plt.imshow(imagen)\n",
    "    plt.title(nombre)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Constantes\n",
    "sift = cv2.xfeatures2d.SIFT_create(contrastThreshold = 0.06)\n",
    "rdm.seed(1)\n",
    "\n",
    "# Modificar segun vuestra ruta\n",
    "ruta_imagenes = '/content/imagenes/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "id": "BPK6JQyaq4Qi"
   },
   "source": [
    "En el siguiente fragmento de c칩digo, definimos una funci칩n que, dadas dos im치genes:\n",
    "- En primer lugar, calcula los puntos clave de cada imagen (key points). Estos puntos son aquellos suficientemente distintivos, es decir, que representan una caracter칤stica 칰nica y estable en una imagen.\n",
    "- A continuaci칩n, calculamos la correspondencia de puntos clave. Esto nos devuelve una estructura (DMatch) que contiene los k mejores puntos coincidentes para cada rasgo de la Imagen 1 dentro de la Imagen 2.\n",
    "- Por 칰ltimo, dibuja las im치genes con la correspondencia de puntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "id": "Bm8yY0zjj5uY",
    "outputId": "1009ddf8-9f3e-46dd-bb65-f1c3d26f4933"
   },
   "outputs": [],
   "source": [
    "def drawMatches(imagen1, imagen2, improve=True):\n",
    "\n",
    "    # Calculamos los descriptores\n",
    "    kp1, des1 = sift.detectAndCompute(imagen1,None)\n",
    "    kp2, des2 = sift.detectAndCompute(imagen2,None)\n",
    "\n",
    "    # Emparejamos descriptores\n",
    "    matches = cv2.BFMatcher().knnMatch(des1, des2, k = 2)\n",
    "\n",
    "    # Aplicar ratio de 0.7 (Lowe)\n",
    "    if improve:\n",
    "        good_matches = []\n",
    "        for m,n in matches:\n",
    "            if m.distance < 0.7*n.distance:\n",
    "                good_matches.append([m])\n",
    "    else:\n",
    "        good_matches = np.array(matches)\n",
    "\n",
    "    # img4 = cv2.drawMatchesKnn(imagen1, kp1, imagen2, kp2, good_matches[:100],outImg=None,flags=2)\n",
    "    img4 = myCustomDrawMatchesKnn(imagen1,kp1,imagen2,kp2,good_matches[:100])\n",
    "    show_img(img4, 'KnnMatch')\n",
    "\n",
    "img1 = read_img(ruta_imagenes+ 'alhambra1.jpg')\n",
    "img2 = read_img(ruta_imagenes+ 'alhambra2.jpg')\n",
    "\n",
    "drawMatches(img1, img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "id": "P1x06viYwp38"
   },
   "source": [
    "En el fragmento de c칩digo anterior, justo despu칠s de llamar a `drawMatchesKnn`, hay una l칤nea comentada 游땚. La siguiente tarea consiste en implementar esa funci칩n (que debe cumplir el mismo prop칩sito) y sustituir la llamada. La siguiente plantilla har치 que sea m치s sencillo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "id": "R7iWn3Dh2rE4"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "def myCustomDrawMatchesKnn(i1, kp1, i2, kp2, matches, thickness=1):\n",
    "    \"\"\"\n",
    "    Dibuja coincidencias entre dos im치genes manualmente, reemplazando cv2.drawMatchesKnn.\n",
    "\n",
    "    Args:\n",
    "        i1 (np.ndarray): Primera imagen.\n",
    "        kp1 (tuple): Puntos clave de la primera imagen.\n",
    "        i2 (np.ndarray): Segunda imagen.\n",
    "        kp2 (tuple): Puntos clave de la segunda imagen.\n",
    "        matches (list): Lista de coincidencias (DMatch).\n",
    "        thickness (int): Grosor de las l칤neas.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: La imagen combinada con las l칤neas dibujadas.\n",
    "    \"\"\"\n",
    "\n",
    "    img_out = None\n",
    "\n",
    "    # --- 1. Dibujar ambas im치genes ---\n",
    "\n",
    "    # --- 1. 1. Preparar un marco (imagen negra) donde quepan ambas im치genes.\n",
    "    alto1, ancho1, canal1 = i1.shape\n",
    "    alto2, ancho2, canal2 = i2.shape\n",
    "\n",
    "    alto = max(alto1, alto2)\n",
    "    ancho = ancho1 + ancho2\n",
    "    frame = np.zeros((alto,ancho,3), dtype=np.uint8)\n",
    "\n",
    "    # --- 1. 2. Pegar ambas im치genes en el marco, una al lado de otra\n",
    "\n",
    "    frame[0:alto1, 0:ancho1, 0:canal1] = i1\n",
    "    frame[0:alto2, ancho1:, 0:canal2] = i2\n",
    "\n",
    "    # --- 2. Dibujar las L칤neas ---\n",
    "\n",
    "    for match in matches:\n",
    "        # Los matches filtrados por Lowe ya son una lista de listas [[DMatch]],\n",
    "        # por lo que tomamos el primer (y 칰nico) objeto DMatch\n",
    "      m = match[0]\n",
    "        # --- 2.1. Calcular ambos puntos en la imagen\n",
    "        # https://docs.opencv.org/4.x/d4/de0/classcv_1_1DMatch.html\n",
    "      puntosI1 = kp1[m.queryIdx].pt\n",
    "      puntosI2 = kp2[m.trainIdx].pt\n",
    "      xI1 = int(puntosI1[0])\n",
    "      yI1 = int(puntosI1[1])\n",
    "      xI2 = int(puntosI2[0])\n",
    "      yI2 = int(puntosI2[1])\n",
    "        # --- 2.2. Dibujar ambos puntos en la imagen, unidos por una l칤nea de\n",
    "        # de color aleatorio\n",
    "        # https://docs.opencv.org/4.x/dc/da5/tutorial_py_drawing_functions.html\n",
    "      img_out = cv2.line(frame, (xI1, yI1) , (xI2 + ancho1, yI2)  , (rdm.randint(0, 255),rdm.randint(0, 255),rdm.randint(0, 255)) ,thickness)\n",
    "\n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "id": "lv9McfPcyh3Q"
   },
   "source": [
    "Pero, 쯣ara qu칠 sirve todo esto? A continuaci칩n, veremos como calcular las equivalencias de puntos clave entre varias im치genes para posteriormente aplicar una serie de operaciones. De esta forma podremos construir mosaicos de forma parecida a como vuestro tel칠fono m칩vil toma fotos panor치micas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "id": "jgIFFJVife6W"
   },
   "outputs": [],
   "source": [
    "# Mueve la imagen img al centro del marco framde\n",
    "def move_to_center(img, frame):\n",
    "    # Se obtienen las dimensiones de la imagen central\n",
    "    height_frame, width_frame, B = frame.shape\n",
    "    height_img, width_img, A = img.shape\n",
    "\n",
    "    # Se calculan las coordenadas de inicio de la imagen central\n",
    "    y_displacement = height_frame/2 - height_img/2\n",
    "    x_displacement = width_frame/2 - width_img/2\n",
    "\n",
    "    # Se crea una matriz 3x3 con los valores a 0 menos la diagonal a 1 y los\n",
    "    # valores de la traslaci칩n\n",
    "    m0 = np.array([[1, 0, x_displacement], [0, 1, y_displacement], [0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "    # BORDER_CONSTANT para rellenar de negro\n",
    "    frame = cv2.warpPerspective(img, m0, (width_frame, height_frame), dst=frame, borderMode=cv2.BORDER_CONSTANT)\n",
    "\n",
    "    return frame, m0\n",
    "\n",
    "# Elimina los m치rgenes negros de una imagen\n",
    "def crop_image(img):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Nos quedamos con los colores distintos de negro\n",
    "    _, thresh = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
    "    # Obtenemos el contorno\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Se calculan las esquinas\n",
    "    x, y, w, h = cv2.boundingRect(np.concatenate(contours))\n",
    "    # Limitamos la imagen\n",
    "    return img[y:y+h,x:x+w]\n",
    "\n",
    "def knnMatch(i1, i2, improve=True):\n",
    "    # Creamos el objeto de correspondencias\n",
    "    bf = cv2.BFMatcher()\n",
    "\n",
    "    # Calculamos los descriptores\n",
    "    kp1, des1 = sift.detectAndCompute(i1,None)\n",
    "    kp2, des2 = sift.detectAndCompute(i2,None)\n",
    "\n",
    "    # Emparejamos descriptores\n",
    "    matches = bf.knnMatch(des1, des2, k = 2)\n",
    "\n",
    "    # Aplicar ratio de 0.7 (Lowe)\n",
    "    if improve:\n",
    "        good = []\n",
    "        for m,n in matches:\n",
    "            if m.distance < 0.7*n.distance:\n",
    "                good.append([m])\n",
    "    else:\n",
    "        good = np.array(matches)\n",
    "\n",
    "    return ((kp1,des1),(kp2,des2), good)\n",
    "\n",
    "def get_homeography(i1,i2):\n",
    "\n",
    "    # Se calculan las correspondencias\n",
    "    kpdes1, kpdes2, matches = knnMatch(i1,i2,improve=True)\n",
    "\n",
    "    kp1, des1 = kpdes1\n",
    "    kp2, des2 = kpdes2\n",
    "\n",
    "    # Comprobamos tener el m칤nimo para realizar homograf칤a\n",
    "    if len(matches)<4:\n",
    "        return -1\n",
    "\n",
    "    # Cambiamos el formato de los puntos\n",
    "    src_pts = np.float32([ kp1[m[0].queryIdx].pt for m in matches ]).reshape(-1,1,2)\n",
    "    dst_pts = np.float32([ kp2[m[0].trainIdx].pt for m in matches ]).reshape(-1,1,2)\n",
    "\n",
    "    # Calculamos homograf칤a\n",
    "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 1)\n",
    "\n",
    "    return M\n",
    "\n",
    "# Compone el mosaico paso a paso, pegando una imagen detr치s de otra\n",
    "def mosaico_R(imagenes):\n",
    "\n",
    "    # Se calcula el ancho del mosaico como la suma de todos los anchos de las im치genes\n",
    "    height = sum([i.shape[0] for i in imagenes])\n",
    "    width = sum([i.shape[1] for i in imagenes])\n",
    "\n",
    "    # construimos lienzo o marco\n",
    "    frame = np.zeros((height,width,3), dtype=np.uint8)\n",
    "\n",
    "    # Movemos primera imagen al centro\n",
    "    img, m0 = move_to_center(imagenes[0],frame)\n",
    "\n",
    "    # Calculamos homograf칤as y llevamos im치genes al mosaico una a una\n",
    "    for i in range(1, len(imagenes)):\n",
    "        M = get_homeography(imagenes[i],img)\n",
    "        img = cv2.warpPerspective(imagenes[i], M, (width, height), dst=img, borderMode=cv2.BORDER_TRANSPARENT)\n",
    "\n",
    "    # Recortamos los bordes\n",
    "    img = crop_image(img)\n",
    "    return img\n",
    "\n",
    "# Calcula previamente todas las homograf칤as necesarias para trasladar cada imagen\n",
    "# al mosaico y por 칰ltimo las traslada\n",
    "def mosaico_M(imagenes):\n",
    "    # Se calcula el ancho del mosaico como la suma de todos los anchos de las im치genes\n",
    "    height = sum([i.shape[0] for i in imagenes])\n",
    "    width = sum([i.shape[1] for i in imagenes])\n",
    "\n",
    "    # construimos lienzo o marco\n",
    "    frame = np.zeros((height,width,3), dtype=np.uint8)\n",
    "\n",
    "    # Obtenemos la homograf칤a necesaria para llevar la imagen al centro del marco\n",
    "    img, m0 = move_to_center(imagenes[0],frame)\n",
    "\n",
    "    homografias = []\n",
    "    homografias.append(m0)\n",
    "\n",
    "    # Calculamos todas las homeograf칤as necesarias para formar el mosaico\n",
    "    for i in range(1, len(imagenes)):\n",
    "        # Homograf칤a de im치genes dos a dos\n",
    "        M = get_homeography(imagenes[i], imagenes[i-1])\n",
    "        # Multiplicamos por la homograf칤a del paso anterior\n",
    "        new_M = np.matmul(m0, M)\n",
    "        homografias.append(new_M)\n",
    "        m0 = new_M\n",
    "\n",
    "    # Trasladamos todas las im치genes al marco\n",
    "    for i in range(len(imagenes)):\n",
    "        img = cv2.warpPerspective(imagenes[i], homografias[i], (width, height), dst=img, borderMode=cv2.BORDER_TRANSPARENT)\n",
    "\n",
    "    # Recortamos los bordes\n",
    "    img = crop_image(img)\n",
    "    return img\n",
    "\n",
    "def calcularMosaicos( imagenes ):\n",
    "    im = mosaico_R(imagenes)\n",
    "    show_img(im, 'mosaico_R')\n",
    "    im = mosaico_M(imagenes)\n",
    "    show_img(im, 'mosaico_M')\n",
    "\n",
    "img1 = read_img(ruta_imagenes+'alhambra1.jpg')\n",
    "img2 = read_img(ruta_imagenes+'alhambra2.jpg')\n",
    "img3 = read_img(ruta_imagenes+'alhambra3.jpg')\n",
    "\n",
    "calcularMosaicos([img1,img2,img3])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
